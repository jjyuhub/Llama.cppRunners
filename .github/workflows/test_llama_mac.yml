name: Build and Test llama.cpp on macOS

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build-and-test:
    runs-on: macos-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2  # Clones the current repository

    - name: Clone llama.cpp repository
      run: |
        git clone https://github.com/ggml-org/llama.cpp.git  # Clones the official llama.cpp repository
        cd llama.cpp
        git submodule update --init --recursive  # Initializes and updates submodules if any

    - name: Set up environment
      run: |
        # Install dependencies
        brew install cmake
        brew install gcc
        brew install wget
        brew install libomp

    - name: Build llama.cpp
      run: |
        # Navigate to the llama.cpp directory
        cd $GITHUB_WORKSPACE/llama.cpp
        mkdir -p build
        cd build
        cmake ..  # Configure the project
        cmake --build . --parallel $(sysctl -n hw.ncpu)  # Build with all available CPU cores
        ls -la  # List files to verify build

    - name: Verify if llama-run is built
      run: |
        # Check if llama-run binary exists
        if [ -f ./build/bin/llama-run ]; then
          echo "llama-run is built successfully."
        else
          echo "llama-run not found. Build might have failed."
          exit 1
        fi

    - name: Run llama with test prompt
      run: |
        # Run a test if llama-run exists
        if [ -f ./build/bin/llama-run ]; then
          ./build/bin/llama-run file://models/deepseek-r1-distill/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf "What is DeepSeek R1?"
        else
          echo "llama-run not found. Skipping test."
        fi
