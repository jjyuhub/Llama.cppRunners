name: Llama.cpp Test on macOS

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build-and-test:
    runs-on: macos-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Set up Homebrew
      run: |
        /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
        brew update

    - name: Install Dependencies
      run: |
        brew install cmake gcc wget libomp

    - name: Download Llama.cpp
      run: |
        git clone https://github.com/ggerganov/llama.cpp.git
        cd llama.cpp
        git submodule update --init --recursive
        
    - name: Build Llama.cpp
      run: |
        cd llama.cpp
        mkdir -p build
        cd build
        cmake ..
        cmake --build . --parallel $(sysctl -n hw.ncpu)
        ls -la ./bin  # Verify that the binary exists
    
    - name: Download Model (skip if no token is required)
      run: |
        mkdir -p ~/llama.cpp/models/deepseek-r1-distill/
        wget "https://huggingface.co/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF/resolve/main/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf" \
        -O ~/llama.cpp/models/deepseek-r1-distill/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf

    - name: Run Inference
      run: |
        cd llama.cpp
        ls
        ls -la ./bin/llama-run 
        ls -la ./build/bin/llama-run 
        ./build/bin/llama-run file://models/deepseek-r1-distill/DeepSeek-R1-Distill-Qwen-1.5B-Q4_K_M.gguf "What is DeepSeek R1?"
